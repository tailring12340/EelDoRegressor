{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c411da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import *\n",
    "from sklearn.preprocessing import *\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.dates import DateFormatter\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# 모델명(= 파일명) 설정\n",
    "model_name = 'test230410-02_LSTMJaponicaAll'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34d5ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_squared 평가 함수\n",
    "def r_squared(y_true, y_pred):\n",
    "    ss_res = K.sum(K.square(y_true - y_pred))\n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - ss_res/(ss_tot + K.epsilon()))\n",
    "\n",
    "# 모델 평가 함수\n",
    "def grapeNEva(model, X_test_shape, y_test):\n",
    "    X_pred = model.predict(X_test_shape)\n",
    "\n",
    "    # 그래프 생성\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(y_test, label='actual')  # x축에 년월일, y축에 값\n",
    "    plt.plot(X_pred, color='red', label='prediction')  # x축에 년월일, y축에 시분\n",
    "    plt.xlabel('날짜')\n",
    "    plt.ylabel('DO')\n",
    "    plt.title('시계열')\n",
    "    plt.legend(['y_test','X_pred'])\n",
    "    plt.show()\n",
    "    \n",
    "    # 평가 생성\n",
    "    result = model.evaluate(X_test_shape, y_test)\n",
    "    print(\"MSE // MAE // R-squared \", result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf24177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#자포니카 훈련 데이터\n",
    "japonica_training_food_supply_tb = pd.read_csv(\"eeldata/data/Training/Origin/Management/Japonica/food_supply_tb.csv\")\n",
    "japonica_training_sensor_val_tb = pd.read_csv(\"eeldata/data/Training/Origin/Sensor/Japonica/sensor_val_tb.csv\")\n",
    "\n",
    "#자포니카 검증 데이터\n",
    "japonica_validation_food_supply_tb = pd.read_csv(\"eeldata/data/Validation/Origin/Management/Japonica/food_supply_tb.csv\")\n",
    "japonica_validation_sensor_val_tb = pd.read_csv(\"eeldata/data/Validation/Origin/Sensor/Japonica/sensor_val_tb.csv\")\n",
    "\n",
    "#자포니카 훈련 데이터 시계열 변환\n",
    "japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].apply(str)\n",
    "japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "japonica_training_food_supply_tb['feed_dt'] = pd.to_datetime(japonica_training_food_supply_tb['feed_dt'], format='%Y%m%d%H%M', errors='raise')\n",
    "japonica_training_food_supply_tb[\"feed_dt\"] = japonica_training_food_supply_tb[\"feed_dt\"].apply(str)\n",
    "japonica_training_food_supply_tb[\"feed_dt\"] = japonica_training_food_supply_tb[\"feed_dt\"].str.slice(start=0, stop=16)\n",
    "\n",
    "#자포니카 검증 데이터 시계열 변환\n",
    "japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].apply(str)\n",
    "japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "japonica_validation_food_supply_tb['feed_dt'] = pd.to_datetime(japonica_validation_food_supply_tb['feed_dt'], format='%Y%m%d%H%M', errors='raise')\n",
    "japonica_validation_food_supply_tb[\"feed_dt\"] = japonica_validation_food_supply_tb[\"feed_dt\"].apply(str)\n",
    "japonica_validation_food_supply_tb[\"feed_dt\"] = japonica_validation_food_supply_tb[\"feed_dt\"].str.slice(start=0, stop=16)\n",
    "\n",
    "# 자포니카 훈련 데이터 및 시계열 데이터 병합\n",
    "japonica_training = pd.merge(left = japonica_training_sensor_val_tb, right = japonica_training_food_supply_tb, how = \"left\", left_on = [\"farm_id\",\"tank_id\", \"mea_dt\"], right_on = [\"farm_id\",\"tank_id\", \"feed_dt\"])\n",
    "japonica_validation = pd.merge(left = japonica_validation_sensor_val_tb, right = japonica_validation_food_supply_tb, how = \"left\", left_on = [\"farm_id\",\"tank_id\", \"mea_dt\"], right_on = [\"farm_id\",\"tank_id\", \"feed_dt\"])\n",
    "\n",
    "#자포니카 훈련 및 검증 데이터 시계열 변환\n",
    "japonica_training['mea_dt'] = pd.to_datetime(japonica_training['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "japonica_validation['mea_dt'] = pd.to_datetime(japonica_validation['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "\n",
    "# 날짜 데이터를 인덱스로 전환\n",
    "japonica_training.set_index('mea_dt', inplace=True)\n",
    "japonica_validation.set_index('mea_dt', inplace=True)\n",
    "\n",
    "# 탱크 순으로 데이터 정렬\n",
    "japonica_training.sort_values(by='tank_id', ascending=True, inplace=True)\n",
    "japonica_validation.sort_values(by='tank_id', ascending=True, inplace=True)\n",
    "\n",
    "# 인덱스 순으로 데이터를 정렬\n",
    "#japonica_training = japonica_training.sort_index()\n",
    "#japonica_validation = japonica_validation.sort_index()\n",
    "\n",
    "japonica_training = japonica_training.groupby('tank_id').apply(lambda x: x.sort_index())\n",
    "japonica_validation = japonica_validation.groupby('tank_id').apply(lambda x: x.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b3f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 features 선택\n",
    "feature_origin = ['tank_id','do_mg','do_temp', 'ph', 'orp', 'co2_mg', 'air_oxy', 'light_ma', 'feed_quantity', 'water_quantity']\n",
    "japonica_training_features = japonica_training[feature_origin]\n",
    "japonica_validation_features = japonica_validation[feature_origin]\n",
    "\n",
    "# nan 값 처리 (먹이를 주지 않았을 경우는 급여량이 0이니까)\n",
    "japonica_training_features = japonica_training_features.fillna(0)\n",
    "japonica_validation_features = japonica_validation_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a79f060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립 변수, 종속 변수 분리\n",
    "feature_Learning = ['do_temp', 'ph', 'orp', 'co2_mg', 'air_oxy', 'light_ma', 'feed_quantity', 'water_quantity']\n",
    "feature_number = len(feature_Learning)\n",
    "\n",
    "japonica_training_features_X = japonica_training_features[feature_Learning]\n",
    "japonica_training_features_y = japonica_training_features[['do_mg']]\n",
    "japonica_validation_features_X = japonica_validation_features[feature_Learning]\n",
    "japonica_validation_features_y = japonica_validation_features[['do_mg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6ef433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM학습을 위해 데이터 reshape를 해야함. reshape를 위해 배열형으로 변환\n",
    "japonica_training_features_X_reshape = np.asarray(japonica_training_features_X, dtype=np.float64)\n",
    "japonica_validation_features_X_reshape = np.asarray(japonica_validation_features_X, dtype=np.float64)\n",
    "\n",
    "# 데이터를 3항으로 reshape. (batch_size, timesteps, features)\n",
    "# batch_size: 한 번에 모델에 입력되는 샘플의 개수\n",
    "# timesteps: 입력되는 시퀀스 데이터의 길이(시간축)\n",
    "# features: 입력되는 데이터의 특성 개수\n",
    "# 말이 어려우니까 쉽게 쓰면 (얼마 만큼의 샘플을, 시간 당 몇 개씩, 항목이 몇 개인가)\n",
    "# (-1 : 있는 만큼의 샘플을, 1 : 시간당 1개씩, 8 : 피처는 8개입니다.)\n",
    "japonica_training_features_X_reshape = japonica_training_features_X_reshape.reshape((-1, 1, feature_number))\n",
    "japonica_validation_features_X_reshape = japonica_validation_features_X_reshape.reshape((-1, 1, feature_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258fd223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nCar: 1113748 nVar: 8\n",
      "nCar: 1113748 nVar: 1\n",
      "nCar: 1113748 nVar: 8\n",
      "nCar: 1113748 nVar: 1\n"
     ]
    }
   ],
   "source": [
    "# shape확인\n",
    "nCar = japonica_training_features_X_reshape.shape[0] # 데이터 개수\n",
    "nVar = japonica_training_features_X_reshape.shape[2] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )\n",
    "\n",
    "nCar = japonica_training_features_y.shape[0] # 데이터 개수\n",
    "nVar = japonica_training_features_y.shape[1] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )\n",
    "\n",
    "# shape확인\n",
    "nCar = japonica_validation_features_X_reshape.shape[0] # 데이터 개수\n",
    "nVar = japonica_validation_features_X_reshape.shape[2] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )\n",
    "\n",
    "nCar = japonica_validation_features_y.shape[0] # 데이터 개수\n",
    "nVar = japonica_validation_features_y.shape[1] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "825c7504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 08:46:57.466255: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 08:46:57.855348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7951 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 1g.10gb, pci bus id: 0000:d5:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 128)            70144     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 64)             49408     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 132,001\n",
      "Trainable params: 132,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 08:46:58.732962: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 08:47:02.665850: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "    1/17403 [..............................] - ETA: 23:42:50 - loss: 63.7928 - mae: 7.6860 - r_squared: -12.5423"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 08:47:03.534295: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17403/17403 [==============================] - 318s 18ms/step - loss: 3.1272 - mae: 1.3768 - r_squared: 0.2818 - val_loss: 2.8136 - val_mae: 1.3119 - val_r_squared: -511496.7812\n",
      "Epoch 2/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 2.6541 - mae: 1.2746 - r_squared: 0.3878 - val_loss: 2.5703 - val_mae: 1.2514 - val_r_squared: -575538.5000\n",
      "Epoch 3/200\n",
      "17403/17403 [==============================] - 314s 18ms/step - loss: 2.5310 - mae: 1.2338 - r_squared: 0.4156 - val_loss: 2.4338 - val_mae: 1.2099 - val_r_squared: -282698.9375\n",
      "Epoch 4/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 2.4384 - mae: 1.2027 - r_squared: 0.4362 - val_loss: 2.4035 - val_mae: 1.1843 - val_r_squared: -423919.1250\n",
      "Epoch 5/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 2.3612 - mae: 1.1778 - r_squared: 0.4540 - val_loss: 2.2885 - val_mae: 1.1612 - val_r_squared: -397266.9688\n",
      "Epoch 6/200\n",
      "17403/17403 [==============================] - 314s 18ms/step - loss: 2.2959 - mae: 1.1565 - r_squared: 0.4684 - val_loss: 2.2267 - val_mae: 1.1254 - val_r_squared: -207849.2500\n",
      "Epoch 7/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 2.2447 - mae: 1.1396 - r_squared: 0.4802 - val_loss: 2.2016 - val_mae: 1.1330 - val_r_squared: -249822.0781\n",
      "Epoch 8/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 2.1973 - mae: 1.1232 - r_squared: 0.4908 - val_loss: 2.1327 - val_mae: 1.0965 - val_r_squared: -189911.1875\n",
      "Epoch 9/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 2.1502 - mae: 1.1070 - r_squared: 0.5021 - val_loss: 2.1352 - val_mae: 1.1036 - val_r_squared: -259106.2969\n",
      "Epoch 10/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 2.1006 - mae: 1.0907 - r_squared: 0.5132 - val_loss: 2.0492 - val_mae: 1.0768 - val_r_squared: -220105.6406\n",
      "Epoch 11/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 2.0475 - mae: 1.0732 - r_squared: 0.5254 - val_loss: 2.0061 - val_mae: 1.0622 - val_r_squared: -311208.8125\n",
      "Epoch 12/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 2.0075 - mae: 1.0595 - r_squared: 0.5346 - val_loss: 1.9519 - val_mae: 1.0426 - val_r_squared: -202808.2969\n",
      "Epoch 13/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 1.9700 - mae: 1.0469 - r_squared: 0.5430 - val_loss: 1.9492 - val_mae: 1.0437 - val_r_squared: -293331.8750\n",
      "Epoch 14/200\n",
      "17403/17403 [==============================] - 314s 18ms/step - loss: 1.9433 - mae: 1.0376 - r_squared: 0.5490 - val_loss: 1.8860 - val_mae: 1.0201 - val_r_squared: -251546.2812\n",
      "Epoch 15/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 1.9147 - mae: 1.0277 - r_squared: 0.5560 - val_loss: 1.9294 - val_mae: 1.0392 - val_r_squared: -211921.4062\n",
      "Epoch 16/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 1.8906 - mae: 1.0188 - r_squared: 0.5615 - val_loss: 1.8361 - val_mae: 1.0031 - val_r_squared: -220239.6562\n",
      "Epoch 17/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 1.8664 - mae: 1.0107 - r_squared: 0.5672 - val_loss: 1.8523 - val_mae: 1.0080 - val_r_squared: -318632.9062\n",
      "Epoch 18/200\n",
      "17403/17403 [==============================] - 308s 18ms/step - loss: 1.8463 - mae: 1.0035 - r_squared: 0.5717 - val_loss: 1.8308 - val_mae: 0.9966 - val_r_squared: -175395.6250\n",
      "Epoch 19/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 1.8264 - mae: 0.9960 - r_squared: 0.5762 - val_loss: 1.7703 - val_mae: 0.9783 - val_r_squared: -232746.4844\n",
      "Epoch 20/200\n",
      "17403/17403 [==============================] - 313s 18ms/step - loss: 1.8072 - mae: 0.9892 - r_squared: 0.5806 - val_loss: 1.8617 - val_mae: 1.0052 - val_r_squared: -263028.4375\n",
      "Epoch 21/200\n",
      "17403/17403 [==============================] - 314s 18ms/step - loss: 1.7939 - mae: 0.9847 - r_squared: 0.5836 - val_loss: 1.7268 - val_mae: 0.9680 - val_r_squared: -271347.0000\n",
      "Epoch 22/200\n",
      "17403/17403 [==============================] - 310s 18ms/step - loss: 1.7768 - mae: 0.9786 - r_squared: 0.5877 - val_loss: 1.7918 - val_mae: 0.9811 - val_r_squared: -203351.6719\n",
      "Epoch 23/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 1.7645 - mae: 0.9743 - r_squared: 0.5903 - val_loss: 1.7489 - val_mae: 0.9722 - val_r_squared: -207664.3750\n",
      "Epoch 24/200\n",
      "17403/17403 [==============================] - 314s 18ms/step - loss: 1.7525 - mae: 0.9704 - r_squared: 0.5934 - val_loss: 1.8137 - val_mae: 0.9861 - val_r_squared: -214986.9688\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 25/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 1.5724 - mae: 0.9086 - r_squared: 0.6349 - val_loss: 1.5622 - val_mae: 0.9051 - val_r_squared: -188260.1250\n",
      "Epoch 26/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 1.5588 - mae: 0.9032 - r_squared: 0.6381 - val_loss: 1.5464 - val_mae: 0.8995 - val_r_squared: -208733.1562\n",
      "Epoch 27/200\n",
      "17403/17403 [==============================] - 314s 18ms/step - loss: 1.5508 - mae: 0.9002 - r_squared: 0.6397 - val_loss: 1.5421 - val_mae: 0.8974 - val_r_squared: -193471.7031\n",
      "Epoch 28/200\n",
      "17403/17403 [==============================] - 306s 18ms/step - loss: 1.5443 - mae: 0.8976 - r_squared: 0.6412 - val_loss: 1.5340 - val_mae: 0.8946 - val_r_squared: -228483.7812\n",
      "Epoch 29/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 1.5381 - mae: 0.8950 - r_squared: 0.6423 - val_loss: 1.5294 - val_mae: 0.8932 - val_r_squared: -225279.9219\n",
      "Epoch 30/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 1.5328 - mae: 0.8932 - r_squared: 0.6437 - val_loss: 1.5211 - val_mae: 0.8890 - val_r_squared: -189615.8906\n",
      "Epoch 31/200\n",
      "17403/17403 [==============================] - 310s 18ms/step - loss: 1.5271 - mae: 0.8911 - r_squared: 0.6450 - val_loss: 1.5288 - val_mae: 0.8905 - val_r_squared: -194535.8906\n",
      "Epoch 32/200\n",
      "17403/17403 [==============================] - 313s 18ms/step - loss: 1.5228 - mae: 0.8889 - r_squared: 0.6463 - val_loss: 1.5235 - val_mae: 0.8893 - val_r_squared: -207314.6094\n",
      "Epoch 33/200\n",
      "17403/17403 [==============================] - 308s 18ms/step - loss: 1.5187 - mae: 0.8875 - r_squared: 0.6468 - val_loss: 1.5096 - val_mae: 0.8846 - val_r_squared: -215135.9844\n",
      "Epoch 34/200\n",
      "17403/17403 [==============================] - 310s 18ms/step - loss: 1.5142 - mae: 0.8859 - r_squared: 0.6482 - val_loss: 1.5083 - val_mae: 0.8839 - val_r_squared: -206878.3906\n",
      "Epoch 35/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 1.5107 - mae: 0.8843 - r_squared: 0.6488 - val_loss: 1.5046 - val_mae: 0.8828 - val_r_squared: -208210.2188\n",
      "Epoch 36/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 1.5068 - mae: 0.8826 - r_squared: 0.6501 - val_loss: 1.5057 - val_mae: 0.8834 - val_r_squared: -201873.3750\n",
      "Epoch 37/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 1.5028 - mae: 0.8814 - r_squared: 0.6511 - val_loss: 1.5024 - val_mae: 0.8817 - val_r_squared: -200046.2344\n",
      "Epoch 38/200\n",
      "17403/17403 [==============================] - 307s 18ms/step - loss: 1.4997 - mae: 0.8800 - r_squared: 0.6515 - val_loss: 1.4992 - val_mae: 0.8796 - val_r_squared: -175650.5312\n",
      "Epoch 39/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 1.4960 - mae: 0.8787 - r_squared: 0.6521 - val_loss: 1.4927 - val_mae: 0.8771 - val_r_squared: -222880.0938\n",
      "Epoch 40/200\n",
      "17403/17403 [==============================] - 314s 18ms/step - loss: 1.4930 - mae: 0.8775 - r_squared: 0.6531 - val_loss: 1.4978 - val_mae: 0.8794 - val_r_squared: -255592.0625\n",
      "Epoch 41/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 1.4904 - mae: 0.8764 - r_squared: 0.6531 - val_loss: 1.4894 - val_mae: 0.8748 - val_r_squared: -196259.1094\n",
      "Epoch 42/200\n",
      "17403/17403 [==============================] - 313s 18ms/step - loss: 1.4864 - mae: 0.8750 - r_squared: 0.6547 - val_loss: 1.4876 - val_mae: 0.8739 - val_r_squared: -214026.4531\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17403/17403 [==============================] - 310s 18ms/step - loss: 1.4832 - mae: 0.8739 - r_squared: 0.6552 - val_loss: 1.4789 - val_mae: 0.8728 - val_r_squared: -202148.3906\n",
      "Epoch 44/200\n",
      "17403/17403 [==============================] - 308s 18ms/step - loss: 1.4803 - mae: 0.8730 - r_squared: 0.6560 - val_loss: 1.4761 - val_mae: 0.8691 - val_r_squared: -191416.4688\n",
      "Epoch 45/200\n",
      "17403/17403 [==============================] - 313s 18ms/step - loss: 1.4783 - mae: 0.8715 - r_squared: 0.6565 - val_loss: 1.4702 - val_mae: 0.8693 - val_r_squared: -229327.4688\n",
      "Epoch 46/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 1.4742 - mae: 0.8704 - r_squared: 0.6575 - val_loss: 1.4677 - val_mae: 0.8676 - val_r_squared: -205959.3438\n",
      "Epoch 47/200\n",
      "17403/17403 [==============================] - 308s 18ms/step - loss: 1.4723 - mae: 0.8695 - r_squared: 0.6578 - val_loss: 1.4694 - val_mae: 0.8674 - val_r_squared: -212160.7344\n",
      "Epoch 48/200\n",
      "17403/17403 [==============================] - 306s 18ms/step - loss: 1.4692 - mae: 0.8686 - r_squared: 0.6585 - val_loss: 1.4615 - val_mae: 0.8659 - val_r_squared: -196964.0781\n",
      "Epoch 49/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 1.4670 - mae: 0.8675 - r_squared: 0.6591 - val_loss: 1.4679 - val_mae: 0.8678 - val_r_squared: -248036.8906\n",
      "Epoch 50/200\n",
      "17403/17403 [==============================] - 310s 18ms/step - loss: 1.4639 - mae: 0.8665 - r_squared: 0.6597 - val_loss: 1.4543 - val_mae: 0.8642 - val_r_squared: -197715.6406\n",
      "Epoch 51/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 1.4621 - mae: 0.8657 - r_squared: 0.6600 - val_loss: 1.4528 - val_mae: 0.8633 - val_r_squared: -188412.3906\n",
      "Epoch 52/200\n",
      "17403/17403 [==============================] - 314s 18ms/step - loss: 1.4590 - mae: 0.8644 - r_squared: 0.6607 - val_loss: 1.4748 - val_mae: 0.8682 - val_r_squared: -203545.2656\n",
      "Epoch 53/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 1.4561 - mae: 0.8635 - r_squared: 0.6612 - val_loss: 1.4555 - val_mae: 0.8634 - val_r_squared: -193296.9688\n",
      "Epoch 54/200\n",
      "17403/17403 [==============================] - 310s 18ms/step - loss: 1.4547 - mae: 0.8630 - r_squared: 0.6618 - val_loss: 1.4414 - val_mae: 0.8573 - val_r_squared: -194979.1562\n",
      "Epoch 55/200\n",
      "17403/17403 [==============================] - 305s 18ms/step - loss: 1.4520 - mae: 0.8619 - r_squared: 0.6622 - val_loss: 1.4429 - val_mae: 0.8597 - val_r_squared: -223029.2188\n",
      "Epoch 56/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 1.4492 - mae: 0.8609 - r_squared: 0.6631 - val_loss: 1.4464 - val_mae: 0.8580 - val_r_squared: -200345.0625\n",
      "Epoch 57/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 1.4464 - mae: 0.8596 - r_squared: 0.6637 - val_loss: 1.4383 - val_mae: 0.8580 - val_r_squared: -204946.4844\n",
      "Epoch 58/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 1.4444 - mae: 0.8590 - r_squared: 0.6641 - val_loss: 1.4384 - val_mae: 0.8558 - val_r_squared: -182135.4531\n",
      "Epoch 59/200\n",
      "17403/17403 [==============================] - 310s 18ms/step - loss: 1.4420 - mae: 0.8580 - r_squared: 0.6649 - val_loss: 1.4426 - val_mae: 0.8571 - val_r_squared: -198679.0625\n",
      "Epoch 60/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 1.4394 - mae: 0.8570 - r_squared: 0.6651 - val_loss: 1.4420 - val_mae: 0.8586 - val_r_squared: -199799.9375\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 61/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 1.4162 - mae: 0.8487 - r_squared: 0.6707 - val_loss: 1.4141 - val_mae: 0.8475 - val_r_squared: -200537.1719\n",
      "Epoch 62/200\n",
      "17403/17403 [==============================] - 308s 18ms/step - loss: 1.4147 - mae: 0.8479 - r_squared: 0.6709 - val_loss: 1.4145 - val_mae: 0.8475 - val_r_squared: -209025.4219\n",
      "Epoch 63/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 1.4145 - mae: 0.8478 - r_squared: 0.6712 - val_loss: 1.4129 - val_mae: 0.8475 - val_r_squared: -204316.1719\n",
      "Epoch 64/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 1.4141 - mae: 0.8477 - r_squared: 0.6712 - val_loss: 1.4131 - val_mae: 0.8472 - val_r_squared: -208236.5312\n",
      "Epoch 65/200\n",
      "17403/17403 [==============================] - 306s 18ms/step - loss: 1.4138 - mae: 0.8477 - r_squared: 0.6714 - val_loss: 1.4123 - val_mae: 0.8470 - val_r_squared: -211883.6875\n",
      "Epoch 66/200\n",
      "17403/17403 [==============================] - 310s 18ms/step - loss: 1.4135 - mae: 0.8475 - r_squared: 0.6713 - val_loss: 1.4140 - val_mae: 0.8478 - val_r_squared: -204182.3281\n",
      "Epoch 67/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 1.4134 - mae: 0.8474 - r_squared: 0.6714 - val_loss: 1.4120 - val_mae: 0.8468 - val_r_squared: -201966.8125\n",
      "Epoch 68/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 1.4129 - mae: 0.8473 - r_squared: 0.6715 - val_loss: 1.4117 - val_mae: 0.8467 - val_r_squared: -207493.8125\n",
      "Epoch 69/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 1.4124 - mae: 0.8472 - r_squared: 0.6715 - val_loss: 1.4125 - val_mae: 0.8477 - val_r_squared: -200645.0625\n",
      "Epoch 70/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 1.4121 - mae: 0.8470 - r_squared: 0.6715 - val_loss: 1.4111 - val_mae: 0.8465 - val_r_squared: -207672.4531\n",
      "Epoch 71/200\n",
      "17403/17403 [==============================] - 316s 18ms/step - loss: 1.4119 - mae: 0.8469 - r_squared: 0.6719 - val_loss: 1.4128 - val_mae: 0.8468 - val_r_squared: -216929.4219\n",
      "Epoch 72/200\n",
      "17403/17403 [==============================] - 309s 18ms/step - loss: 1.4118 - mae: 0.8468 - r_squared: 0.6717 - val_loss: 1.4110 - val_mae: 0.8467 - val_r_squared: -209288.0625\n",
      "Epoch 73/200\n",
      "17403/17403 [==============================] - 306s 18ms/step - loss: 1.4113 - mae: 0.8467 - r_squared: 0.6717 - val_loss: 1.4110 - val_mae: 0.8467 - val_r_squared: -212086.7344\n",
      "Epoch 74/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 1.4111 - mae: 0.8466 - r_squared: 0.6721 - val_loss: 1.4093 - val_mae: 0.8461 - val_r_squared: -199319.1719\n",
      "Epoch 75/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 1.4111 - mae: 0.8466 - r_squared: 0.6717 - val_loss: 1.4106 - val_mae: 0.8465 - val_r_squared: -217448.5625\n",
      "Epoch 76/200\n",
      "17403/17403 [==============================] - 313s 18ms/step - loss: 1.4107 - mae: 0.8464 - r_squared: 0.6720 - val_loss: 1.4099 - val_mae: 0.8465 - val_r_squared: -208372.7188\n",
      "Epoch 77/200\n",
      "17403/17403 [==============================] - 308s 18ms/step - loss: 1.4104 - mae: 0.8464 - r_squared: 0.6721 - val_loss: 1.4097 - val_mae: 0.8460 - val_r_squared: -211952.1719\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 78/200\n",
      "17403/17403 [==============================] - 315s 18ms/step - loss: 1.4080 - mae: 0.8455 - r_squared: 0.6727 - val_loss: 1.4073 - val_mae: 0.8452 - val_r_squared: -207916.4844\n",
      "Epoch 79/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 1.4076 - mae: 0.8454 - r_squared: 0.6728 - val_loss: 1.4073 - val_mae: 0.8453 - val_r_squared: -207402.2500\n",
      "Epoch 80/200\n",
      "17403/17403 [==============================] - 314s 18ms/step - loss: 1.4075 - mae: 0.8453 - r_squared: 0.6728 - val_loss: 1.4072 - val_mae: 0.8452 - val_r_squared: -209287.2812\n",
      "Epoch 81/200\n",
      "17403/17403 [==============================] - 312s 18ms/step - loss: 1.4075 - mae: 0.8453 - r_squared: 0.6726 - val_loss: 1.4073 - val_mae: 0.8453 - val_r_squared: -209258.1875\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 82/200\n",
      "17403/17403 [==============================] - 311s 18ms/step - loss: 1.4072 - mae: 0.8453 - r_squared: 0.6728 - val_loss: 1.4071 - val_mae: 0.8452 - val_r_squared: -208962.0312\n",
      "Epoch 83/200\n",
      "17403/17403 [==============================] - 315s 18ms/step - loss: 1.4071 - mae: 0.8452 - r_squared: 0.6725 - val_loss: 1.4071 - val_mae: 0.8452 - val_r_squared: -208919.8125\n",
      "Epoch 84/200\n",
      "17403/17403 [==============================] - 308s 18ms/step - loss: 1.4071 - mae: 0.8452 - r_squared: 0.6729 - val_loss: 1.4071 - val_mae: 0.8452 - val_r_squared: -209047.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "17403/17403 [==============================] - 307s 18ms/step - loss: 1.4071 - mae: 0.8452 - r_squared: 0.6727 - val_loss: 1.4071 - val_mae: 0.8452 - val_r_squared: -208791.8125\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 86/200\n",
      "17403/17403 [==============================] - 315s 18ms/step - loss: 1.4071 - mae: 0.8452 - r_squared: 0.6728 - val_loss: 1.4071 - val_mae: 0.8452 - val_r_squared: -208824.2500\n",
      "Epoch 87/200\n",
      "17403/17403 [==============================] - 313s 18ms/step - loss: 1.4071 - mae: 0.8452 - r_squared: 0.6730 - val_loss: 1.4071 - val_mae: 0.8452 - val_r_squared: -208825.8750\n",
      "Epoch 00087: early stopping\n"
     ]
    }
   ],
   "source": [
    "# LSTM 모델 생성\n",
    "model = Sequential()\n",
    "# 결과값이 128개 -> 64개 -> 32개 -> 1개(회귀)\n",
    "# input_shape=(timesteps, input_dim)\n",
    "# timesteps : 시계열 데이터의 시간 스텝 수.\n",
    "#       예를 들어, 1분 단위로 측정한 센서 데이터가 있다면 timesteps는 60.\n",
    "# input_dim : 특성(feature)의 수.\n",
    "model.add(LSTM(128, input_shape=(1, feature_number), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='linear'))\n",
    " \n",
    "model.summary()\n",
    "\n",
    "# mae와 r_squared 평가함수 추가.\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae', r_squared])\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_name + '_best.h5', monitor='val_loss', save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "\n",
    "# ModelCheckpoint : 검증 손실이 낮아진 경우에 최적의 모델을 저장\n",
    "# EarlyStopping : 검증 손실이 일정 기간동안 향상되지 않으면 학습을 조기 종료\n",
    "# ReduceLROnPlateau : 검증 손실이 개선되지 않으면 학습률을 조정하는 등의 동작 수행.\n",
    "\n",
    "hist = model.fit(japonica_training_features_X_reshape, japonica_training_features_y, epochs = 200, batch_size = 64, validation_data=(japonica_validation_features_X_reshape, japonica_validation_features_y), callbacks=[checkpoint, early_stop, reduce_lr])\n",
    "model.save(model_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4ff34c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_squared가 따로 만들어서 추가해준 함수기 때문에 불러올 때도 추가해서 불러야한다.\n",
    "model = load_model(model_name+'.h5', custom_objects={'r_squared': r_squared})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "996c41aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.24283440e-01  2.85025954e-01 -3.27398963e-02 ... -1.10691810e+00\n",
      "   2.60139201e-02  2.10927859e-01]\n",
      " [ 5.87002337e-01  1.02850996e-01  8.26751471e-01 ...  2.49881887e+00\n",
      "   1.72667683e-03  4.11479175e-02]\n",
      " [-3.10738776e-02  7.36445263e-02 -1.37922794e-01 ...  1.06519349e-01\n",
      "   3.66394132e-01  1.51509896e-01]\n",
      " ...\n",
      " [ 1.80503204e-01  1.70041651e-01 -6.02991357e-02 ...  1.04903571e-01\n",
      "   2.19143070e-02  3.50711793e-02]\n",
      " [-1.68298498e-01  1.32985180e-02  8.33430052e-01 ...  1.65544078e-01\n",
      "   1.07369773e-01  3.71188447e-02]\n",
      " [-3.46547365e-02 -5.49853370e-02  7.58038938e-01 ... -1.05512403e-01\n",
      "   7.26546571e-02  6.50715530e-02]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 가중치를 통해 변수 중요도 획득\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "print(weights)\n",
    "\n",
    "\n",
    "# 변수 중요도 시각화\n",
    "fig, ax = plt.subplots(figsize=(30, 4))\n",
    "ax.bar(range(feature_number), weights[:, 0])\n",
    "ax.set_xticks(range(feature_number))\n",
    "ax.set_xticklabels(feature_Learning)\n",
    "ax.set_ylabel('Weight')\n",
    "ax.set_title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38152d1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'tuple'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4029482/1289315163.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrapeNEva\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaponica_validation_features_X_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaponica_validation_features_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4029482/1457513188.py\u001b[0m in \u001b[0;36mgrapeNEva\u001b[0;34m(model, X_test_shape, y_test)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 그래프 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'actual'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# x축에 년월일, y축에 값\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# x축에 년월일, y축에 시분\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'날짜'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2755\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2757\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2758\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1634\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1635\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_autoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   2281\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2285\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'_child{len(self._children)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   2304\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2305\u001b[0m         \"\"\"\n\u001b[0;32m-> 2306\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2308\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0;34m\"\"\"Return the `~matplotlib.path.Path` associated with this line.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mxconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_xunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/tf2.6.0-keras2.6.0-py3.8-cuda11.3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAAGfCAYAAAAakuCUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAT7ElEQVR4nO3dX4jl91nH8c/TrFGotYXuCiW7moBb27UKrUOs9MJCq2xysXuhSBaKVkL3xoh/ihBpqZJe1aKCEP+sWKqCjbEXMmAkFxopiCmZUg0mJTJEbTYKWWvMTbFp9PHinNXpdHfndHNmdh/m9YKF8/ud75zzXHyZ3ff+zvymujsAAADM8ZobPQAAAADfGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADD7BlyVfWJqnqhqv7hKs9XVf1mVW1X1ZNV9Y71jwkAAMBlq1yR+2SS09d4/q4kJ5d/zif57Vc/FgAAAFezZ8h192eS/Mc1lpxN8oe98HiSN1TVm9Y1IAAAAF/ryBpe47Ykz+04vrg892+7F1bV+Syu2uW1r33t97/lLW9Zw9sDAADM87nPfe7fu/vY9XztOkJuZd19IcmFJNnY2Oitra2DfHsAAICbRlX9y/V+7TruWvl8khM7jo8vzwEAALAP1hFym0l+Ynn3yncmeam7v+5jlQAAAKzHnh+trKpPJXl3kqNVdTHJLyf5piTp7t9J8kiSu5NsJ/lykp/ar2EBAABYIeS6+9wez3eSn17bRAAAAFzTOj5aCQAAwAEScgAAAMMIOQAAgGGEHAAAwDBCDgAAYBghBwAAMIyQAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDCDkAAIBhhBwAAMAwQg4AAGAYIQcAADCMkAMAABhGyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDBCDgAAYBghBwAAMIyQAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDCDkAAIBhhBwAAMAwQg4AAGAYIQcAADCMkAMAABhGyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDBCDgAAYBghBwAAMIyQAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDCDkAAIBhVgq5qjpdVc9U1XZV3X+F57+jqh6rqs9X1ZNVdff6RwUAACBZIeSq6pYkDya5K8mpJOeq6tSuZR9O8nB3vz3JPUl+a92DAgAAsLDKFbk7k2x397Pd/XKSh5Kc3bWmk3zb8vHrk/zr+kYEAABgp1VC7rYkz+04vrg8t9OvJHlfVV1M8kiSn7nSC1XV+araqqqtS5cuXce4AAAArOtmJ+eSfLK7jye5O8kfVdXXvXZ3X+juje7eOHbs2JreGgAA4HBZJeSeT3Jix/Hx5bmd7k3ycJJ0998m+ZYkR9cxIAAAAF9rlZB7IsnJqrqjqm7N4mYmm7vWfDHJe5Kkqt6aRcj57CQAAMA+2DPkuvuVJPcleTTJF7K4O+VTVfVAVZ1ZLvtgkg9U1d8n+VSS93d379fQAAAAh9mRVRZ19yNZ3MRk57mP7Hj8dJJ3rXc0AAAArmRdNzsBAADggAg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDCDkAAIBhhBwAAMAwQg4AAGAYIQcAADCMkAMAABhGyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDBCDgAAYBghBwAAMIyQAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDCDkAAIBhhBwAAMAwQg4AAGAYIQcAADCMkAMAABhGyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDBCDgAAYBghBwAAMIyQAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDCDkAAIBhhBwAAMAwQg4AAGAYIQcAADCMkAMAABhGyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDArhVxVna6qZ6pqu6ruv8qaH6+qp6vqqar64/WOCQAAwGVH9lpQVbckeTDJDye5mOSJqtrs7qd3rDmZ5JeSvKu7X6yqb9+vgQEAAA67Va7I3Zlku7uf7e6XkzyU5OyuNR9I8mB3v5gk3f3CescEAADgslVC7rYkz+04vrg8t9Obk7y5qv6mqh6vqtNXeqGqOl9VW1W1denSpeubGAAA4JBb181OjiQ5meTdSc4l+b2qesPuRd19obs3unvj2LFja3prAACAw2WVkHs+yYkdx8eX53a6mGSzu7/a3f+U5B+zCDsAAADWbJWQeyLJyaq6o6puTXJPks1da/4si6txqaqjWXzU8tn1jQkAAMBle4Zcd7+S5L4kjyb5QpKHu/upqnqgqs4slz2a5EtV9XSSx5L8Ynd/ab+GBgAAOMyqu2/IG29sbPTW1tYNeW8AAIAbrao+190b1/O167rZCQAAAAdEyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDBCDgAAYBghBwAAMIyQAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDCDkAAIBhhBwAAMAwQg4AAGAYIQcAADCMkAMAABhGyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDBCDgAAYBghBwAAMIyQAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDCDkAAIBhhBwAAMAwQg4AAGAYIQcAADCMkAMAABhGyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDBCDgAAYBghBwAAMIyQAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDrBRyVXW6qp6pqu2quv8a6360qrqqNtY3IgAAADvtGXJVdUuSB5PcleRUknNVdeoK616X5GeTfHbdQwIAAPD/Vrkid2eS7e5+trtfTvJQkrNXWPfRJB9L8l9rnA8AAIBdVgm525I8t+P44vLc/6mqdyQ50d1/fq0XqqrzVbVVVVuXLl36hocFAABgDTc7qarXJPn1JB/ca213X+juje7eOHbs2Kt9awAAgENplZB7PsmJHcfHl+cue12StyX566r65yTvTLLphicAAAD7Y5WQeyLJyaq6o6puTXJPks3LT3b3S919tLtv7+7bkzye5Ex3b+3LxAAAAIfcniHX3a8kuS/Jo0m+kOTh7n6qqh6oqjP7PSAAAABf68gqi7r7kSSP7Dr3kausfferHwsAAICredU3OwEAAOBgCTkAAIBhhBwAAMAwQg4AAGAYIQcAADCMkAMAABhGyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDBCDgAAYBghBwAAMIyQAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDCDkAAIBhhBwAAMAwQg4AAGAYIQcAADCMkAMAABhGyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDBCDgAAYBghBwAAMIyQAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDCDkAAIBhhBwAAMAwQg4AAGAYIQcAADCMkAMAABhGyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDBCDgAAYBghBwAAMIyQAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMCuFXFWdrqpnqmq7qu6/wvO/UFVPV9WTVfWXVfWd6x8VAACAZIWQq6pbkjyY5K4kp5Kcq6pTu5Z9PslGd39fkk8n+dV1DwoAAMDCKlfk7kyy3d3PdvfLSR5Kcnbngu5+rLu/vDx8PMnx9Y4JAADAZauE3G1JnttxfHF57mruTfIXV3qiqs5X1VZVbV26dGn1KQEAAPg/a73ZSVW9L8lGko9f6fnuvtDdG929cezYsXW+NQAAwKFxZIU1zyc5seP4+PLc16iq9yb5UJIf6u6vrGc8AAAAdlvlitwTSU5W1R1VdWuSe5Js7lxQVW9P8rtJznT3C+sfEwAAgMv2DLnufiXJfUkeTfKFJA9391NV9UBVnVku+3iSb03yp1X1d1W1eZWXAwAA4FVa5aOV6e5Hkjyy69xHdjx+75rnAgAA4CrWerMTAAAA9p+QAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDCDkAAIBhhBwAAMAwQg4AAGAYIQcAADCMkAMAABhGyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDBCDgAAYBghBwAAMIyQAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDCDkAAIBhhBwAAMAwQg4AAGAYIQcAADCMkAMAABhGyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDBCDgAAYBghBwAAMIyQAwAAGEbIAQAADCPkAAAAhhFyAAAAwwg5AACAYYQcAADAMEIOAABgGCEHAAAwjJADAAAYRsgBAAAMI+QAAACGEXIAAADDCDkAAIBhhBwAAMAwQg4AAGAYIQcAADCMkAMAABhGyAEAAAyzUshV1emqeqaqtqvq/is8/81V9SfL5z9bVbevfVIAAACSrBByVXVLkgeT3JXkVJJzVXVq17J7k7zY3d+V5DeSfGzdgwIAALCwyhW5O5Nsd/ez3f1ykoeSnN215mySP1g+/nSS91RVrW9MAAAALjuywprbkjy34/hikh+42prufqWqXkryxiT/vnNRVZ1Pcn55+JWq+ofrGRr22dHs2rtwE7E/uVnZm9zM7E9uVt99vV+4SsitTXdfSHIhSapqq7s3DvL9YRX2Jjcz+5Oblb3Jzcz+5GZVVVvX+7WrfLTy+SQndhwfX5674pqqOpLk9Um+dL1DAQAAcHWrhNwTSU5W1R1VdWuSe5Js7lqzmeQnl49/LMlfdXevb0wAAAAu2/OjlcufebsvyaNJbknyie5+qqoeSLLV3ZtJfj/JH1XVdpL/yCL29nLhVcwN+8ne5GZmf3Kzsje5mdmf3Kyue2+WC2cAAACzrPQLwQEAALh5CDkAAIBh9j3kqup0VT1TVdtVdf8Vnv/mqvqT5fOfrarb93smSFbam79QVU9X1ZNV9ZdV9Z03Yk4Op7325451P1pVXVVuq82BWGVvVtWPL79/PlVVf3zQM3I4rfD3+ndU1WNV9fnl3+1334g5OXyq6hNV9cLVfod2Lfzmcu8+WVXvWOV19zXkquqWJA8muSvJqSTnqurUrmX3Jnmxu78ryW8k+dh+zgTJynvz80k2uvv7knw6ya8e7JQcVivuz1TV65L8bJLPHuyEHFar7M2qOpnkl5K8q7u/J8nPHfScHD4rft/8cJKHu/vtWdyY77cOdkoOsU8mOX2N5+9KcnL553yS317lRff7itydSba7+9nufjnJQ0nO7lpzNskfLB9/Osl7qqr2eS7Yc29292Pd/eXl4eNZ/A5FOAirfO9Mko9m8Z9f/3WQw3GorbI3P5Dkwe5+MUm6+4UDnpHDaZW92Um+bfn49Un+9QDn4xDr7s9kcWf/qzmb5A974fEkb6iqN+31uvsdcrcleW7H8cXluSuu6e5XkryU5I37PBessjd3ujfJX+zrRPD/9tyfy49dnOjuPz/IwTj0Vvne+eYkb66qv6mqx6vqWv8LDeuyyt78lSTvq6qLSR5J8jMHMxrs6Rv9d2mSFX6PHBx2VfW+JBtJfuhGzwJJUlWvSfLrSd5/g0eBKzmSxceD3p3FJxk+U1Xf293/eSOHgiTnknyyu3+tqn4wi9+B/Lbu/p8bPRhcj/2+Ivd8khM7jo8vz11xTVUdyeJS95f2eS5YZW+mqt6b5ENJznT3Vw5oNthrf74uyduS/HVV/XOSdybZdMMTDsAq3zsvJtns7q929z8l+ccswg720yp7894kDydJd/9tkm9JcvRApoNrW+nfpbvtd8g9keRkVd1RVbdm8YOlm7vWbCb5yeXjH0vyV+23lLP/9tybVfX2JL+bRcT5GQ8O0jX3Z3e/1N1Hu/v27r49i5/hPNPdWzdmXA6RVf5e/7Msrsalqo5m8VHLZw9wRg6nVfbmF5O8J0mq6q1ZhNylA50SrmwzyU8s7175ziQvdfe/7fVF+/rRyu5+paruS/JokluSfKK7n6qqB5Jsdfdmkt/P4tL2dhY/BHjPfs4Eycp78+NJvjXJny7vv/PF7j5zw4bm0Fhxf8KBW3FvPprkR6rq6ST/neQXu9snbdhXK+7NDyb5var6+SxufPJ+Fw84CFX1qSz+g+vo8mc0fznJNyVJd/9OFj+zeXeS7SRfTvJTK72u/QsAADDLvv9CcAAAANZLyAEAAAwj5AAAAIYRcgAAAMMIOQAAgGGEHAAAwDBCDgAAYJj/Bd1Npiyu9xk8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grapeNEva(model, japonica_validation_features_X_reshape, japonica_validation_features_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf98b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자포니카 검증 데이터의 한 개 탱크\n",
    "tank = 1\n",
    "japonica_validation_features_tank = japonica_validation_features[japonica_validation_features['tank_id']==tank]\n",
    "\n",
    "# 하루 동안의 데이터 추출\n",
    "one_day_data = japonica_validation_features_tank.loc['2021-08-27 00:00:00':'2021-08-27 23:59:59']\n",
    "oneday_X_test = one_day_data[feature_Learning]\n",
    "oneday_y_test = one_day_data[['do_mg']]\n",
    "\n",
    "oneday_X_test_reshape = np.asarray(oneday_X_test, dtype=np.float64)\n",
    "oneday_X_test_reshape = oneday_X_test_reshape.reshape((-1, 1, feature_number))\n",
    "\n",
    "# shape확인\n",
    "nCar = oneday_X_test_reshape.shape[0] # 데이터 개수\n",
    "nVar = oneday_X_test_reshape.shape[2] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )\n",
    "\n",
    "nCar = oneday_y_test.shape[0] # 데이터 개수\n",
    "nVar = oneday_y_test.shape[1] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca1335",
   "metadata": {},
   "outputs": [],
   "source": [
    "grapeNEva(model, oneday_X_test_reshape, oneday_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4739fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.6.0-keras2.6.0-py3.8-cuda11.3",
   "language": "python",
   "name": "tf2.6.0-keras2.6.0-py3.8-cuda11.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
