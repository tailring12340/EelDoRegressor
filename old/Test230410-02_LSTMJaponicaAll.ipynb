{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import *\n",
    "from sklearn.preprocessing import *\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.dates import DateFormatter\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# 모델명(= 파일명) 설정\n",
    "model_name = 'test230410-02_LSTMJaponicaAll'\n",
    "\n",
    "# 한글 글꼴 경로 설정\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf'  # 원하는 한글 글꼴 파일 경로로 수정해주세요\n",
    "font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "plt.rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_squared 평가 함수\n",
    "def r_squared(y_true, y_pred):\n",
    "    ss_res = K.sum(K.square(y_true - y_pred))\n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - ss_res/(ss_tot + K.epsilon()))\n",
    "\n",
    "# 모델 평가 함수\n",
    "def grapeNEva(model, X_test_shape, y_test):\n",
    "    X_pred = model.predict(X_test_shape)\n",
    "\n",
    "    # 그래프 생성\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(y_test.xs(1, level='tank_id').index, y_test, label='actual')  # x축에 년월일, y축에 값\n",
    "    plt.plot(y_test.xs(1, level='tank_id').index, X_pred, color='red', label='prediction')  # x축에 년월일, y축에 시분\n",
    "    plt.xlabel('날짜')\n",
    "    plt.ylabel('DO')\n",
    "    plt.title('시계열')\n",
    "    plt.legend(['y_test','X_pred'])\n",
    "    plt.show()\n",
    "    \n",
    "    # 평가 생성\n",
    "    result = model.evaluate(X_test_shape, y_test)\n",
    "    print(\"MSE // MAE // R-squared \", result)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#자포니카 훈련 데이터\n",
    "japonica_training_food_supply_tb = pd.read_csv(\"E:/kimwoojae/Research/DO Regressor/dataset/japonica_training_food_supply_tb.csv\")\n",
    "japonica_training_sensor_val_tb = pd.read_csv(\"E:/kimwoojae/Research/DO Regressor/dataset/japonica_training_sensor_val_tb.csv\")\n",
    "\n",
    "#자포니카 검증 데이터\n",
    "japonica_validation_food_supply_tb = pd.read_csv(\"E:/kimwoojae/Research/DO Regressor/dataset/japonica_validation_food_supply_tb.csv\")\n",
    "japonica_validation_sensor_val_tb = pd.read_csv(\"E:/kimwoojae/Research/DO Regressor/dataset/japonica_validation_sensor_val_tb.csv\")\n",
    "\n",
    "#자포니카 훈련 데이터 시계열 변환\n",
    "japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].apply(str)\n",
    "japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "japonica_training_food_supply_tb['feed_dt'] = pd.to_datetime(japonica_training_food_supply_tb['feed_dt'], format='%Y%m%d%H%M', errors='raise')\n",
    "japonica_training_food_supply_tb[\"feed_dt\"] = japonica_training_food_supply_tb[\"feed_dt\"].apply(str)\n",
    "japonica_training_food_supply_tb[\"feed_dt\"] = japonica_training_food_supply_tb[\"feed_dt\"].str.slice(start=0, stop=16)\n",
    "\n",
    "#자포니카 검증 데이터 시계열 변환\n",
    "japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].apply(str)\n",
    "japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "japonica_validation_food_supply_tb['feed_dt'] = pd.to_datetime(japonica_validation_food_supply_tb['feed_dt'], format='%Y%m%d%H%M', errors='raise')\n",
    "japonica_validation_food_supply_tb[\"feed_dt\"] = japonica_validation_food_supply_tb[\"feed_dt\"].apply(str)\n",
    "japonica_validation_food_supply_tb[\"feed_dt\"] = japonica_validation_food_supply_tb[\"feed_dt\"].str.slice(start=0, stop=16)\n",
    "\n",
    "# 자포니카 훈련 데이터 및 시계열 데이터 병합\n",
    "japonica_training = pd.merge(left = japonica_training_sensor_val_tb, right = japonica_training_food_supply_tb, how = \"left\", left_on = [\"farm_id\",\"tank_id\", \"mea_dt\"], right_on = [\"farm_id\",\"tank_id\", \"feed_dt\"])\n",
    "japonica_validation = pd.merge(left = japonica_validation_sensor_val_tb, right = japonica_validation_food_supply_tb, how = \"left\", left_on = [\"farm_id\",\"tank_id\", \"mea_dt\"], right_on = [\"farm_id\",\"tank_id\", \"feed_dt\"])\n",
    "\n",
    "#자포니카 훈련 및 검증 데이터 시계열 변환\n",
    "japonica_training['mea_dt'] = pd.to_datetime(japonica_training['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "japonica_validation['mea_dt'] = pd.to_datetime(japonica_validation['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "\n",
    "# 날짜 데이터를 인덱스로 전환\n",
    "japonica_training.set_index('mea_dt', inplace=True)\n",
    "japonica_validation.set_index('mea_dt', inplace=True)\n",
    "\n",
    "# 탱크 순으로 데이터 정렬\n",
    "japonica_training.sort_values(by='tank_id', ascending=True, inplace=True)\n",
    "japonica_validation.sort_values(by='tank_id', ascending=True, inplace=True)\n",
    "\n",
    "# 인덱스 순으로 데이터를 정렬\n",
    "#japonica_training = japonica_training.sort_index()\n",
    "#japonica_validation = japonica_validation.sort_index()\n",
    "\n",
    "japonica_training = japonica_training.groupby('tank_id').apply(lambda x: x.sort_index())\n",
    "japonica_validation = japonica_validation.groupby('tank_id').apply(lambda x: x.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 features 선택\n",
    "feature_origin = ['tank_id','do_mg','do_temp', 'ph', 'orp', 'co2_mg', 'air_oxy', 'light_ma', 'feed_quantity', 'water_quantity']\n",
    "japonica_training_features = japonica_training[feature_origin]\n",
    "japonica_validation_features = japonica_validation[feature_origin]\n",
    "\n",
    "# nan 값 처리 (먹이를 주지 않았을 경우는 급여량이 0이니까)\n",
    "japonica_training_features = japonica_training_features.fillna(0)\n",
    "japonica_validation_features = japonica_validation_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립 변수, 종속 변수 분리\n",
    "feature_Learning = ['do_temp', 'ph', 'orp', 'co2_mg', 'air_oxy', 'light_ma', 'feed_quantity', 'water_quantity']\n",
    "feature_number = len(feature_Learning)\n",
    "\n",
    "japonica_training_features_X = japonica_training_features[feature_Learning]\n",
    "japonica_training_features_y = japonica_training_features[['do_mg']]\n",
    "japonica_validation_features_X = japonica_validation_features[feature_Learning]\n",
    "japonica_validation_features_y = japonica_validation_features[['do_mg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM학습을 위해 데이터 reshape를 해야함. reshape를 위해 배열형으로 변환\n",
    "japonica_training_features_X_reshape = np.asarray(japonica_training_features_X, dtype=np.float64)\n",
    "japonica_validation_features_X_reshape = np.asarray(japonica_validation_features_X, dtype=np.float64)\n",
    "\n",
    "# 데이터를 3항으로 reshape. (batch_size, timesteps, features)\n",
    "# batch_size: 한 번에 모델에 입력되는 샘플의 개수\n",
    "# timesteps: 입력되는 시퀀스 데이터의 길이(시간축)\n",
    "# features: 입력되는 데이터의 특성 개수\n",
    "# 말이 어려우니까 쉽게 쓰면 (얼마 만큼의 샘플을, 시간 당 몇 개씩, 항목이 몇 개인가)\n",
    "# (-1 : 있는 만큼의 샘플을, 1 : 시간당 1개씩, 8 : 피처는 8개입니다.)\n",
    "japonica_training_features_X_reshape = japonica_training_features_X_reshape.reshape((-1, 1, feature_number))\n",
    "japonica_validation_features_X_reshape = japonica_validation_features_X_reshape.reshape((-1, 1, feature_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nCar: 1113748 nVar: 8\n",
      "nCar: 1113748 nVar: 1\n",
      "nCar: 1113748 nVar: 8\n",
      "nCar: 1113748 nVar: 1\n"
     ]
    }
   ],
   "source": [
    "# shape확인\n",
    "nCar = japonica_training_features_X_reshape.shape[0] # 데이터 개수\n",
    "nVar = japonica_training_features_X_reshape.shape[2] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )\n",
    "\n",
    "nCar = japonica_training_features_y.shape[0] # 데이터 개수\n",
    "nVar = japonica_training_features_y.shape[1] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )\n",
    "\n",
    "# shape확인\n",
    "nCar = japonica_validation_features_X_reshape.shape[0] # 데이터 개수\n",
    "nVar = japonica_validation_features_X_reshape.shape[2] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )\n",
    "\n",
    "nCar = japonica_validation_features_y.shape[0] # 데이터 개수\n",
    "nVar = japonica_validation_features_y.shape[1] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM 모델 학습 (학습시에만 사용, 그외에는 불필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 128)            70144     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 64)             49408     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,001\n",
      "Trainable params: 132,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "17403/17403 [==============================] - 116s 6ms/step - loss: 3.0901 - mae: 1.3720 - r_squared: 0.2917 - val_loss: 2.7637 - val_mae: 1.3154 - val_r_squared: -2004031.6250 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 2.7049 - mae: 1.2881 - r_squared: 0.3767 - val_loss: 2.6752 - val_mae: 1.2665 - val_r_squared: -449270.8438 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 2.6270 - mae: 1.2595 - r_squared: 0.3947 - val_loss: 2.6677 - val_mae: 1.2661 - val_r_squared: -237973.5312 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "17403/17403 [==============================] - 108s 6ms/step - loss: 2.5578 - mae: 1.2353 - r_squared: 0.4101 - val_loss: 2.5313 - val_mae: 1.2311 - val_r_squared: -501581.4688 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 2.4661 - mae: 1.2055 - r_squared: 0.4308 - val_loss: 2.4523 - val_mae: 1.1991 - val_r_squared: -416449.5938 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "17403/17403 [==============================] - 103s 6ms/step - loss: 2.3701 - mae: 1.1755 - r_squared: 0.4523 - val_loss: 2.3491 - val_mae: 1.1750 - val_r_squared: -263966.8438 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 2.2780 - mae: 1.1457 - r_squared: 0.4727 - val_loss: 2.1736 - val_mae: 1.1151 - val_r_squared: -184207.9375 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 2.1968 - mae: 1.1198 - r_squared: 0.4908 - val_loss: 2.1087 - val_mae: 1.0966 - val_r_squared: -379031.5000 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 2.1349 - mae: 1.0996 - r_squared: 0.5055 - val_loss: 2.0667 - val_mae: 1.0857 - val_r_squared: -197291.7188 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "17403/17403 [==============================] - 103s 6ms/step - loss: 2.0838 - mae: 1.0829 - r_squared: 0.5168 - val_loss: 2.0482 - val_mae: 1.0710 - val_r_squared: -339549.0938 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "17403/17403 [==============================] - 110s 6ms/step - loss: 2.0383 - mae: 1.0686 - r_squared: 0.5275 - val_loss: 2.0181 - val_mae: 1.0585 - val_r_squared: -324234.6875 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "17403/17403 [==============================] - 111s 6ms/step - loss: 2.0064 - mae: 1.0577 - r_squared: 0.5349 - val_loss: 1.9383 - val_mae: 1.0374 - val_r_squared: -230435.7500 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "17403/17403 [==============================] - 101s 6ms/step - loss: 1.9755 - mae: 1.0479 - r_squared: 0.5421 - val_loss: 1.9115 - val_mae: 1.0229 - val_r_squared: -201508.3438 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 1.9476 - mae: 1.0375 - r_squared: 0.5482 - val_loss: 1.9321 - val_mae: 1.0339 - val_r_squared: -283774.1250 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.9203 - mae: 1.0283 - r_squared: 0.5545 - val_loss: 1.8988 - val_mae: 1.0179 - val_r_squared: -235829.4375 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.8992 - mae: 1.0205 - r_squared: 0.5592 - val_loss: 1.8361 - val_mae: 0.9981 - val_r_squared: -247322.1250 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 1.8689 - mae: 1.0104 - r_squared: 0.5666 - val_loss: 1.8743 - val_mae: 1.0059 - val_r_squared: -115909.5938 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "17403/17403 [==============================] - 111s 6ms/step - loss: 1.8493 - mae: 1.0037 - r_squared: 0.5711 - val_loss: 1.8000 - val_mae: 0.9892 - val_r_squared: -337745.0625 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 1.8296 - mae: 0.9969 - r_squared: 0.5755 - val_loss: 1.7957 - val_mae: 0.9848 - val_r_squared: -244460.4375 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "17403/17403 [==============================] - 107s 6ms/step - loss: 1.8102 - mae: 0.9900 - r_squared: 0.5797 - val_loss: 1.7942 - val_mae: 0.9884 - val_r_squared: -480064.3438 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 1.7952 - mae: 0.9853 - r_squared: 0.5831 - val_loss: 1.7933 - val_mae: 0.9830 - val_r_squared: -190216.0000 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "17403/17403 [==============================] - 108s 6ms/step - loss: 1.7775 - mae: 0.9787 - r_squared: 0.5874 - val_loss: 1.7448 - val_mae: 0.9642 - val_r_squared: -146551.3281 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "17403/17403 [==============================] - 116s 7ms/step - loss: 1.7634 - mae: 0.9735 - r_squared: 0.5908 - val_loss: 1.7144 - val_mae: 0.9534 - val_r_squared: -167116.0156 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "17403/17403 [==============================] - 108s 6ms/step - loss: 1.7520 - mae: 0.9699 - r_squared: 0.5931 - val_loss: 1.7254 - val_mae: 0.9593 - val_r_squared: -253287.6250 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "17403/17403 [==============================] - 107s 6ms/step - loss: 1.7394 - mae: 0.9648 - r_squared: 0.5964 - val_loss: 1.8284 - val_mae: 0.9934 - val_r_squared: -154709.1562 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "17397/17403 [============================>.] - ETA: 0s - loss: 1.7234 - mae: 0.9589 - r_squared: 0.6001\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "17403/17403 [==============================] - 107s 6ms/step - loss: 1.7233 - mae: 0.9589 - r_squared: 0.6001 - val_loss: 1.7549 - val_mae: 0.9750 - val_r_squared: -192949.6250 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "17403/17403 [==============================] - 115s 7ms/step - loss: 1.5488 - mae: 0.9001 - r_squared: 0.6404 - val_loss: 1.5370 - val_mae: 0.8952 - val_r_squared: -163611.3125 - lr: 1.0000e-04\n",
      "Epoch 28/200\n",
      "17403/17403 [==============================] - 110s 6ms/step - loss: 1.5345 - mae: 0.8939 - r_squared: 0.6434 - val_loss: 1.5321 - val_mae: 0.8951 - val_r_squared: -167500.1406 - lr: 1.0000e-04\n",
      "Epoch 29/200\n",
      "17403/17403 [==============================] - 102s 6ms/step - loss: 1.5262 - mae: 0.8906 - r_squared: 0.6456 - val_loss: 1.5180 - val_mae: 0.8889 - val_r_squared: -183796.9844 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "17403/17403 [==============================] - 101s 6ms/step - loss: 1.5203 - mae: 0.8885 - r_squared: 0.6470 - val_loss: 1.5145 - val_mae: 0.8850 - val_r_squared: -182895.3125 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "17403/17403 [==============================] - 109s 6ms/step - loss: 1.5153 - mae: 0.8865 - r_squared: 0.6478 - val_loss: 1.5078 - val_mae: 0.8845 - val_r_squared: -168434.0312 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "17403/17403 [==============================] - 109s 6ms/step - loss: 1.5100 - mae: 0.8844 - r_squared: 0.6492 - val_loss: 1.5100 - val_mae: 0.8825 - val_r_squared: -190624.1250 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "17403/17403 [==============================] - 108s 6ms/step - loss: 1.5054 - mae: 0.8825 - r_squared: 0.6499 - val_loss: 1.5096 - val_mae: 0.8853 - val_r_squared: -197922.0469 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "17403/17403 [==============================] - 111s 6ms/step - loss: 1.5005 - mae: 0.8808 - r_squared: 0.6510 - val_loss: 1.4966 - val_mae: 0.8790 - val_r_squared: -189735.0312 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "17403/17403 [==============================] - 109s 6ms/step - loss: 1.4962 - mae: 0.8789 - r_squared: 0.6521 - val_loss: 1.4897 - val_mae: 0.8764 - val_r_squared: -230621.9688 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "17403/17403 [==============================] - 110s 6ms/step - loss: 1.4919 - mae: 0.8773 - r_squared: 0.6531 - val_loss: 1.4917 - val_mae: 0.8782 - val_r_squared: -180453.0938 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "17403/17403 [==============================] - 109s 6ms/step - loss: 1.4875 - mae: 0.8755 - r_squared: 0.6541 - val_loss: 1.4809 - val_mae: 0.8725 - val_r_squared: -177641.4062 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 1.4830 - mae: 0.8740 - r_squared: 0.6550 - val_loss: 1.4763 - val_mae: 0.8728 - val_r_squared: -170781.6562 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "17403/17403 [==============================] - 109s 6ms/step - loss: 1.4795 - mae: 0.8725 - r_squared: 0.6561 - val_loss: 1.4742 - val_mae: 0.8698 - val_r_squared: -192937.4062 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "17403/17403 [==============================] - 108s 6ms/step - loss: 1.4754 - mae: 0.8709 - r_squared: 0.6568 - val_loss: 1.4694 - val_mae: 0.8677 - val_r_squared: -196625.1094 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "17403/17403 [==============================] - 109s 6ms/step - loss: 1.4719 - mae: 0.8693 - r_squared: 0.6580 - val_loss: 1.4690 - val_mae: 0.8690 - val_r_squared: -204104.0625 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "17403/17403 [==============================] - 111s 6ms/step - loss: 1.4683 - mae: 0.8680 - r_squared: 0.6589 - val_loss: 1.4629 - val_mae: 0.8655 - val_r_squared: -179529.3281 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "17403/17403 [==============================] - 117s 7ms/step - loss: 1.4650 - mae: 0.8666 - r_squared: 0.6595 - val_loss: 1.4594 - val_mae: 0.8654 - val_r_squared: -172623.3281 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "17403/17403 [==============================] - 108s 6ms/step - loss: 1.4620 - mae: 0.8655 - r_squared: 0.6602 - val_loss: 1.4653 - val_mae: 0.8670 - val_r_squared: -175853.8281 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "17403/17403 [==============================] - 110s 6ms/step - loss: 1.4586 - mae: 0.8640 - r_squared: 0.6607 - val_loss: 1.4509 - val_mae: 0.8623 - val_r_squared: -175374.6406 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "17403/17403 [==============================] - 116s 7ms/step - loss: 1.4554 - mae: 0.8627 - r_squared: 0.6613 - val_loss: 1.4497 - val_mae: 0.8613 - val_r_squared: -197575.1875 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "17403/17403 [==============================] - 122s 7ms/step - loss: 1.4525 - mae: 0.8615 - r_squared: 0.6622 - val_loss: 1.4493 - val_mae: 0.8599 - val_r_squared: -202521.2656 - lr: 1.0000e-04\n",
      "Epoch 48/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 1.4500 - mae: 0.8608 - r_squared: 0.6627 - val_loss: 1.4551 - val_mae: 0.8608 - val_r_squared: -173019.9844 - lr: 1.0000e-04\n",
      "Epoch 49/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 1.4465 - mae: 0.8591 - r_squared: 0.6636 - val_loss: 1.4485 - val_mae: 0.8557 - val_r_squared: -199218.0625 - lr: 1.0000e-04\n",
      "Epoch 50/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 1.4435 - mae: 0.8582 - r_squared: 0.6642 - val_loss: 1.4322 - val_mae: 0.8532 - val_r_squared: -217828.1719 - lr: 1.0000e-04\n",
      "Epoch 51/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 1.4411 - mae: 0.8570 - r_squared: 0.6647 - val_loss: 1.4297 - val_mae: 0.8535 - val_r_squared: -197937.7188 - lr: 1.0000e-04\n",
      "Epoch 52/200\n",
      "17403/17403 [==============================] - 118s 7ms/step - loss: 1.4383 - mae: 0.8561 - r_squared: 0.6656 - val_loss: 1.4293 - val_mae: 0.8529 - val_r_squared: -191686.2656 - lr: 1.0000e-04\n",
      "Epoch 53/200\n",
      "17403/17403 [==============================] - 119s 7ms/step - loss: 1.4357 - mae: 0.8551 - r_squared: 0.6659 - val_loss: 1.4327 - val_mae: 0.8522 - val_r_squared: -193585.2656 - lr: 1.0000e-04\n",
      "Epoch 54/200\n",
      "17403/17403 [==============================] - 111s 6ms/step - loss: 1.4331 - mae: 0.8538 - r_squared: 0.6666 - val_loss: 1.4329 - val_mae: 0.8535 - val_r_squared: -193563.6094 - lr: 1.0000e-04\n",
      "Epoch 55/200\n",
      "17403/17403 [==============================] - 100s 6ms/step - loss: 1.4302 - mae: 0.8527 - r_squared: 0.6675 - val_loss: 1.4214 - val_mae: 0.8490 - val_r_squared: -204206.7812 - lr: 1.0000e-04\n",
      "Epoch 56/200\n",
      "17403/17403 [==============================] - 103s 6ms/step - loss: 1.4282 - mae: 0.8519 - r_squared: 0.6678 - val_loss: 1.4286 - val_mae: 0.8524 - val_r_squared: -209644.2188 - lr: 1.0000e-04\n",
      "Epoch 57/200\n",
      "17403/17403 [==============================] - 99s 6ms/step - loss: 1.4262 - mae: 0.8511 - r_squared: 0.6683 - val_loss: 1.4176 - val_mae: 0.8503 - val_r_squared: -208442.9844 - lr: 1.0000e-04\n",
      "Epoch 58/200\n",
      "17403/17403 [==============================] - 100s 6ms/step - loss: 1.4235 - mae: 0.8502 - r_squared: 0.6692 - val_loss: 1.4315 - val_mae: 0.8529 - val_r_squared: -204944.0781 - lr: 1.0000e-04\n",
      "Epoch 59/200\n",
      "17403/17403 [==============================] - 102s 6ms/step - loss: 1.4211 - mae: 0.8492 - r_squared: 0.6693 - val_loss: 1.4183 - val_mae: 0.8478 - val_r_squared: -225714.2188 - lr: 1.0000e-04\n",
      "Epoch 60/200\n",
      "17403/17403 [==============================] - 108s 6ms/step - loss: 1.4195 - mae: 0.8483 - r_squared: 0.6696 - val_loss: 1.4146 - val_mae: 0.8463 - val_r_squared: -223968.7656 - lr: 1.0000e-04\n",
      "Epoch 61/200\n",
      "17403/17403 [==============================] - 109s 6ms/step - loss: 1.4173 - mae: 0.8475 - r_squared: 0.6704 - val_loss: 1.4131 - val_mae: 0.8440 - val_r_squared: -236625.8125 - lr: 1.0000e-04\n",
      "Epoch 62/200\n",
      "17403/17403 [==============================] - 111s 6ms/step - loss: 1.4147 - mae: 0.8465 - r_squared: 0.6708 - val_loss: 1.4037 - val_mae: 0.8419 - val_r_squared: -218345.4219 - lr: 1.0000e-04\n",
      "Epoch 63/200\n",
      "17403/17403 [==============================] - 114s 7ms/step - loss: 1.4127 - mae: 0.8458 - r_squared: 0.6713 - val_loss: 1.4159 - val_mae: 0.8472 - val_r_squared: -233922.9219 - lr: 1.0000e-04\n",
      "Epoch 64/200\n",
      "17403/17403 [==============================] - 100s 6ms/step - loss: 1.4103 - mae: 0.8447 - r_squared: 0.6718 - val_loss: 1.4016 - val_mae: 0.8436 - val_r_squared: -206273.5625 - lr: 1.0000e-04\n",
      "Epoch 65/200\n",
      "17403/17403 [==============================] - 98s 6ms/step - loss: 1.4087 - mae: 0.8443 - r_squared: 0.6720 - val_loss: 1.4125 - val_mae: 0.8481 - val_r_squared: -199728.9062 - lr: 1.0000e-04\n",
      "Epoch 66/200\n",
      "17403/17403 [==============================] - 101s 6ms/step - loss: 1.4067 - mae: 0.8433 - r_squared: 0.6731 - val_loss: 1.3971 - val_mae: 0.8418 - val_r_squared: -226717.6406 - lr: 1.0000e-04\n",
      "Epoch 67/200\n",
      "17403/17403 [==============================] - 108s 6ms/step - loss: 1.4047 - mae: 0.8425 - r_squared: 0.6735 - val_loss: 1.4006 - val_mae: 0.8423 - val_r_squared: -236189.7188 - lr: 1.0000e-04\n",
      "Epoch 68/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 1.4026 - mae: 0.8420 - r_squared: 0.6742 - val_loss: 1.4080 - val_mae: 0.8450 - val_r_squared: -246299.3906 - lr: 1.0000e-04\n",
      "Epoch 69/200\n",
      "17396/17403 [============================>.] - ETA: 0s - loss: 1.4005 - mae: 0.8411 - r_squared: 0.6744\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "17403/17403 [==============================] - 103s 6ms/step - loss: 1.4004 - mae: 0.8411 - r_squared: 0.6744 - val_loss: 1.3979 - val_mae: 0.8414 - val_r_squared: -204039.6406 - lr: 1.0000e-04\n",
      "Epoch 70/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3769 - mae: 0.8318 - r_squared: 0.6800 - val_loss: 1.3749 - val_mae: 0.8315 - val_r_squared: -212939.5156 - lr: 1.0000e-05\n",
      "Epoch 71/200\n",
      "17403/17403 [==============================] - 107s 6ms/step - loss: 1.3756 - mae: 0.8315 - r_squared: 0.6802 - val_loss: 1.3752 - val_mae: 0.8308 - val_r_squared: -217396.3750 - lr: 1.0000e-05\n",
      "Epoch 72/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 1.3751 - mae: 0.8313 - r_squared: 0.6801 - val_loss: 1.3747 - val_mae: 0.8310 - val_r_squared: -215257.4219 - lr: 1.0000e-05\n",
      "Epoch 73/200\n",
      "17403/17403 [==============================] - 107s 6ms/step - loss: 1.3750 - mae: 0.8312 - r_squared: 0.6802 - val_loss: 1.3740 - val_mae: 0.8308 - val_r_squared: -215479.2812 - lr: 1.0000e-05\n",
      "Epoch 74/200\n",
      "17403/17403 [==============================] - 107s 6ms/step - loss: 1.3746 - mae: 0.8311 - r_squared: 0.6801 - val_loss: 1.3732 - val_mae: 0.8306 - val_r_squared: -212348.8125 - lr: 1.0000e-05\n",
      "Epoch 75/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 1.3744 - mae: 0.8310 - r_squared: 0.6806 - val_loss: 1.3736 - val_mae: 0.8305 - val_r_squared: -223920.4062 - lr: 1.0000e-05\n",
      "Epoch 76/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3741 - mae: 0.8308 - r_squared: 0.6802 - val_loss: 1.3739 - val_mae: 0.8304 - val_r_squared: -223498.7969 - lr: 1.0000e-05\n",
      "Epoch 77/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3739 - mae: 0.8308 - r_squared: 0.6806 - val_loss: 1.3731 - val_mae: 0.8307 - val_r_squared: -211175.7031 - lr: 1.0000e-05\n",
      "Epoch 78/200\n",
      "17403/17403 [==============================] - 103s 6ms/step - loss: 1.3736 - mae: 0.8306 - r_squared: 0.6805 - val_loss: 1.3732 - val_mae: 0.8306 - val_r_squared: -212854.8594 - lr: 1.0000e-05\n",
      "Epoch 79/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3733 - mae: 0.8306 - r_squared: 0.6807 - val_loss: 1.3722 - val_mae: 0.8301 - val_r_squared: -218215.5312 - lr: 1.0000e-05\n",
      "Epoch 80/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 1.3731 - mae: 0.8304 - r_squared: 0.6804 - val_loss: 1.3737 - val_mae: 0.8314 - val_r_squared: -218101.8125 - lr: 1.0000e-05\n",
      "Epoch 81/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 1.3728 - mae: 0.8303 - r_squared: 0.6806 - val_loss: 1.3748 - val_mae: 0.8316 - val_r_squared: -207220.4844 - lr: 1.0000e-05\n",
      "Epoch 82/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3728 - mae: 0.8302 - r_squared: 0.6805 - val_loss: 1.3720 - val_mae: 0.8303 - val_r_squared: -220117.7500 - lr: 1.0000e-05\n",
      "Epoch 83/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3724 - mae: 0.8302 - r_squared: 0.6809 - val_loss: 1.3718 - val_mae: 0.8300 - val_r_squared: -221590.9062 - lr: 1.0000e-05\n",
      "Epoch 84/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 1.3721 - mae: 0.8299 - r_squared: 0.6809 - val_loss: 1.3715 - val_mae: 0.8301 - val_r_squared: -214218.9062 - lr: 1.0000e-05\n",
      "Epoch 85/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3719 - mae: 0.8300 - r_squared: 0.6806 - val_loss: 1.3716 - val_mae: 0.8305 - val_r_squared: -210825.7344 - lr: 1.0000e-05\n",
      "Epoch 86/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 1.3718 - mae: 0.8299 - r_squared: 0.6807 - val_loss: 1.3705 - val_mae: 0.8291 - val_r_squared: -219309.0938 - lr: 1.0000e-05\n",
      "Epoch 87/200\n",
      "17403/17403 [==============================] - 103s 6ms/step - loss: 1.3714 - mae: 0.8297 - r_squared: 0.6808 - val_loss: 1.3718 - val_mae: 0.8294 - val_r_squared: -216155.1406 - lr: 1.0000e-05\n",
      "Epoch 88/200\n",
      "17403/17403 [==============================] - 107s 6ms/step - loss: 1.3713 - mae: 0.8296 - r_squared: 0.6808 - val_loss: 1.3723 - val_mae: 0.8298 - val_r_squared: -233076.8438 - lr: 1.0000e-05\n",
      "Epoch 89/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3710 - mae: 0.8296 - r_squared: 0.6811 - val_loss: 1.3696 - val_mae: 0.8289 - val_r_squared: -224790.7969 - lr: 1.0000e-05\n",
      "Epoch 90/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 1.3708 - mae: 0.8294 - r_squared: 0.6813 - val_loss: 1.3710 - val_mae: 0.8292 - val_r_squared: -224263.8594 - lr: 1.0000e-05\n",
      "Epoch 91/200\n",
      "17403/17403 [==============================] - 108s 6ms/step - loss: 1.3705 - mae: 0.8293 - r_squared: 0.6813 - val_loss: 1.3703 - val_mae: 0.8296 - val_r_squared: -230544.9531 - lr: 1.0000e-05\n",
      "Epoch 92/200\n",
      "17401/17403 [============================>.] - ETA: 0s - loss: 1.3703 - mae: 0.8293 - r_squared: 0.6812\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3702 - mae: 0.8293 - r_squared: 0.6813 - val_loss: 1.3698 - val_mae: 0.8289 - val_r_squared: -225929.7031 - lr: 1.0000e-05\n",
      "Epoch 93/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 1.3679 - mae: 0.8283 - r_squared: 0.6818 - val_loss: 1.3674 - val_mae: 0.8281 - val_r_squared: -220433.4531 - lr: 1.0000e-06\n",
      "Epoch 94/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3676 - mae: 0.8282 - r_squared: 0.6820 - val_loss: 1.3675 - val_mae: 0.8283 - val_r_squared: -219276.0781 - lr: 1.0000e-06\n",
      "Epoch 95/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 1.3676 - mae: 0.8283 - r_squared: 0.6820 - val_loss: 1.3673 - val_mae: 0.8281 - val_r_squared: -218713.1094 - lr: 1.0000e-06\n",
      "Epoch 96/200\n",
      "17398/17403 [============================>.] - ETA: 0s - loss: 1.3676 - mae: 0.8283 - r_squared: 0.6819\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "17403/17403 [==============================] - 103s 6ms/step - loss: 1.3676 - mae: 0.8283 - r_squared: 0.6819 - val_loss: 1.3673 - val_mae: 0.8281 - val_r_squared: -219296.5938 - lr: 1.0000e-06\n",
      "Epoch 97/200\n",
      "17403/17403 [==============================] - 109s 6ms/step - loss: 1.3673 - mae: 0.8281 - r_squared: 0.6820 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -219019.6719 - lr: 1.0000e-07\n",
      "Epoch 98/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 1.3673 - mae: 0.8281 - r_squared: 0.6818 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218715.0000 - lr: 1.0000e-07\n",
      "Epoch 99/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6818 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218516.6406 - lr: 1.0000e-07\n",
      "Epoch 100/200\n",
      "17398/17403 [============================>.] - ETA: 0s - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6817\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "17403/17403 [==============================] - 107s 6ms/step - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6817 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218554.8281 - lr: 1.0000e-07\n",
      "Epoch 101/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6823 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218521.4062 - lr: 1.0000e-08\n",
      "Epoch 102/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6818 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218475.6250 - lr: 1.0000e-08\n",
      "Epoch 103/200\n",
      "17395/17403 [============================>.] - ETA: 0s - loss: 1.3673 - mae: 0.8281 - r_squared: 0.6819\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6818 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218440.7656 - lr: 1.0000e-08\n",
      "Epoch 104/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6820 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218441.0625 - lr: 1.0000e-09\n",
      "Epoch 105/200\n",
      "17403/17403 [==============================] - 105s 6ms/step - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6820 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218440.4844 - lr: 1.0000e-09\n",
      "Epoch 106/200\n",
      "17397/17403 [============================>.] - ETA: 0s - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6817\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6818 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218440.8906 - lr: 1.0000e-09\n",
      "Epoch 107/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6820 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218440.8750 - lr: 1.0000e-10\n",
      "Epoch 108/200\n",
      "17403/17403 [==============================] - 107s 6ms/step - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6821 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218440.8750 - lr: 1.0000e-10\n",
      "Epoch 109/200\n",
      "17403/17403 [==============================] - ETA: 0s - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6821\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "17403/17403 [==============================] - 108s 6ms/step - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6821 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218440.8906 - lr: 1.0000e-10\n",
      "Epoch 110/200\n",
      "17403/17403 [==============================] - 104s 6ms/step - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6818 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218440.8906 - lr: 1.0000e-11\n",
      "Epoch 111/200\n",
      "17403/17403 [==============================] - 106s 6ms/step - loss: 1.3672 - mae: 0.8281 - r_squared: 0.6819 - val_loss: 1.3672 - val_mae: 0.8281 - val_r_squared: -218440.8906 - lr: 1.0000e-11\n",
      "Epoch 111: early stopping\n"
     ]
    }
   ],
   "source": [
    "# LSTM 모델 생성\n",
    "model = Sequential()\n",
    "# 결과값이 128개 -> 64개 -> 32개 -> 1개(회귀)\n",
    "# input_shape=(timesteps, input_dim)\n",
    "# timesteps : 시계열 데이터의 시간 스텝 수.\n",
    "#       예를 들어, 1분 단위로 측정한 센서 데이터가 있다면 timesteps는 60.\n",
    "# input_dim : 특성(feature)의 수.\n",
    "model.add(LSTM(128, input_shape=(1, feature_number), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='linear'))\n",
    " \n",
    "model.summary()\n",
    "\n",
    "# mae와 r_squared 평가함수 추가.\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae', r_squared])\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_name + '_best.h5', monitor='val_loss', save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "\n",
    "# ModelCheckpoint : 검증 손실이 낮아진 경우에 최적의 모델을 저장\n",
    "# EarlyStopping : 검증 손실이 일정 기간동안 향상되지 않으면 학습을 조기 종료\n",
    "# ReduceLROnPlateau : 검증 손실이 개선되지 않으면 학습률을 조정하는 등의 동작 수행.\n",
    "\n",
    "hist = model.fit(japonica_training_features_X_reshape, japonica_training_features_y, epochs = 200, batch_size = 64, validation_data=(japonica_validation_features_X_reshape, japonica_validation_features_y), callbacks=[checkpoint, early_stop, reduce_lr])\n",
    "model.save(model_name+'.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_squared가 따로 만들어서 추가해준 함수기 때문에 불러올 때도 추가해서 불러야한다.\n",
    "model = load_model(model_name+'.h5', custom_objects={'r_squared': r_squared})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.15115513 -1.423476    0.20815381 ... -0.28617075  0.30447656\n",
      "   1.378921  ]\n",
      " [-0.17002365  0.680727    0.249287   ... -0.16355439 -0.01038981\n",
      "  -0.8269054 ]\n",
      " [ 0.3175409   0.05790774  0.14808343 ... -0.06212142  0.06867903\n",
      "  -0.28958967]\n",
      " ...\n",
      " [-0.22084115 -1.618164    0.1830503  ... -0.10487243  0.15136418\n",
      "   1.2733153 ]\n",
      " [ 0.05282611 -0.98099273 -0.0082274  ...  0.03693809  0.07558192\n",
      "   0.5967919 ]\n",
      " [-0.08999687 -1.0153793  -0.10026257 ...  0.06062846  0.09199649\n",
      "   0.53748924]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 가중치를 통해 변수 중요도 획득\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "print(weights)\n",
    "\n",
    "\n",
    "# 변수 중요도 시각화\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.bar(range(feature_number), weights[:, 0])\n",
    "ax.set_xticks(range(feature_number))\n",
    "ax.set_xticklabels(feature_Learning)\n",
    "ax.set_ylabel('Weight')\n",
    "ax.set_title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34805/34805 [==============================] - 61s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.687201 ],\n",
       "       [8.507356 ],\n",
       "       [8.662929 ],\n",
       "       ...,\n",
       "       [8.972927 ],\n",
       "       [8.9576435],\n",
       "       [8.668408 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = model.predict(japonica_validation_features_X_reshape)\n",
    "X_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:551\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[1;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 551\u001b[0m     arr \u001b[39m=\u001b[39m sanitize_array(data, \u001b[39mNone\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    552\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\pandas\\core\\construction.py:607\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    605\u001b[0m             subarr \u001b[39m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m--> 607\u001b[0m subarr \u001b[39m=\u001b[39m _sanitize_ndim(subarr, data, dtype, index, allow_2d\u001b[39m=\u001b[39;49mallow_2d)\n\u001b[0;32m    609\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(subarr, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m    610\u001b[0m     \u001b[39m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\pandas\\core\\construction.py:666\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m--> 666\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    667\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    668\u001b[0m     )\n\u001b[0;32m    669\u001b[0m \u001b[39mif\u001b[39;00m is_object_dtype(dtype) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m    670\u001b[0m     \u001b[39m# i.e. PandasDtype(\"O\")\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (2, 1113748, 1) instead",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m japonica_validation_features_y\u001b[39m.\u001b[39;49mplot(y\u001b[39m=\u001b[39;49m[japonica_validation_features_y\u001b[39m.\u001b[39;49mvalues, X_pred], label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mactual\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m \u001b[39m#X_pred.plot()\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[39m# 그래프 생성\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m#plt.figure(figsize=(15, 7))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m#plt.title('시계열')\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m#plt.legend(['y_test','X_pred'])\u001b[39;00m\n\u001b[0;32m     10\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\pandas\\plotting\\_core.py:961\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    960\u001b[0m \u001b[39m# don't overwrite\u001b[39;00m\n\u001b[1;32m--> 961\u001b[0m data \u001b[39m=\u001b[39m data[y]\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    963\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ABCSeries):\n\u001b[0;32m    964\u001b[0m     label_name \u001b[39m=\u001b[39m label_kw \u001b[39mor\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\pandas\\core\\frame.py:3766\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3764\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3765\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3766\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3768\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3769\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5871\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5868\u001b[0m     keyarr \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39masarray_tuplesafe(keyarr)\n\u001b[0;32m   5870\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 5871\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_indexer_for(keyarr)\n\u001b[0;32m   5872\u001b[0m     keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex(keyarr)[\u001b[39m0\u001b[39m]\n\u001b[0;32m   5873\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5858\u001b[0m, in \u001b[0;36mIndex.get_indexer_for\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   5840\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5841\u001b[0m \u001b[39mGuaranteed return of an indexer even when non-unique.\u001b[39;00m\n\u001b[0;32m   5842\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5855\u001b[0m \u001b[39marray([0, 2])\u001b[39;00m\n\u001b[0;32m   5856\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5857\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 5858\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_indexer(target)\n\u001b[0;32m   5859\u001b[0m indexer, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_indexer_non_unique(target)\n\u001b[0;32m   5860\u001b[0m \u001b[39mreturn\u001b[39;00m indexer\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3726\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3724\u001b[0m method \u001b[39m=\u001b[39m clean_reindex_fill_method(method)\n\u001b[0;32m   3725\u001b[0m orig_target \u001b[39m=\u001b[39m target\n\u001b[1;32m-> 3726\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_cast_listlike_indexer(target)\n\u001b[0;32m   3728\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3730\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6362\u001b[0m, in \u001b[0;36mIndex._maybe_cast_listlike_indexer\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   6358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_cast_listlike_indexer\u001b[39m(\u001b[39mself\u001b[39m, target) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Index:\n\u001b[0;32m   6359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6360\u001b[0m \u001b[39m    Analogue to maybe_cast_indexer for get_indexer instead of get_loc.\u001b[39;00m\n\u001b[0;32m   6361\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6362\u001b[0m     \u001b[39mreturn\u001b[39;00m ensure_index(target)\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7125\u001b[0m, in \u001b[0;36mensure_index\u001b[1;34m(index_like, copy)\u001b[0m\n\u001b[0;32m   7123\u001b[0m         \u001b[39mreturn\u001b[39;00m Index(index_like, copy\u001b[39m=\u001b[39mcopy, tupleize_cols\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   7124\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 7125\u001b[0m     \u001b[39mreturn\u001b[39;00m Index(index_like, copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:556\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[1;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_raise_scalar_data_error(data) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    555\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mData must be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n\u001b[1;32m--> 556\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIndex data must be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    557\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[0;32m    558\u001b[0m arr \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(arr)\n",
      "\u001b[1;31mValueError\u001b[0m: Index data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "\n",
    "japonica_validation_features_y.plot(y=[japonica_validation_features_y.values, X_pred], label='actual')\n",
    "#X_pred.plot()\n",
    "    # 그래프 생성\n",
    "#plt.figure(figsize=(15, 7))\n",
    "#plt.plot(japonica_validation_features_y.index, japonica_validation_features_y, label='actual')  # x축에 년월일, y축에 값\n",
    "#plt.xlabel('날짜')\n",
    "#plt.ylabel('DO')\n",
    "#plt.title('시계열')\n",
    "#plt.legend(['y_test','X_pred'])\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34805/34805 [==============================] - 60s 2ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (222751,) and (1113748, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grapeNEva(model, japonica_validation_features_X_reshape, japonica_validation_features_y)\n",
      "Cell \u001b[1;32mIn[27], line 13\u001b[0m, in \u001b[0;36mgrapeNEva\u001b[1;34m(model, X_test_shape, y_test)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# 그래프 생성\u001b[39;00m\n\u001b[0;32m     12\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m, \u001b[39m7\u001b[39m))\n\u001b[1;32m---> 13\u001b[0m plt\u001b[39m.\u001b[39;49mplot(y_test\u001b[39m.\u001b[39;49mxs(\u001b[39m1\u001b[39;49m, level\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtank_id\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mindex, y_test, label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mactual\u001b[39;49m\u001b[39m'\u001b[39;49m)  \u001b[39m# x축에 년월일, y축에 값\u001b[39;00m\n\u001b[0;32m     14\u001b[0m plt\u001b[39m.\u001b[39mplot(y_test\u001b[39m.\u001b[39mxs(\u001b[39m1\u001b[39m, level\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtank_id\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mindex, X_pred, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mred\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# x축에 년월일, y축에 시분\u001b[39;00m\n\u001b[0;32m     15\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39m날짜\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\matplotlib\\pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2810\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2812\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[0;32m   2813\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[0;32m   2814\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1688\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1690\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[0;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
      "File \u001b[1;32mc:\\Users\\rladn\\anaconda3\\envs\\doRegressor\\Lib\\site-packages\\matplotlib\\axes\\_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39mupdate_units(y)\n\u001b[0;32m    503\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m--> 504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y must have same first dimension, but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhave shapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y can be no greater than 2D, but have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (222751,) and (1113748, 1)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grapeNEva(model, japonica_validation_features_X_reshape, japonica_validation_features_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자포니카 검증 데이터의 한 개 탱크\n",
    "tank = 1\n",
    "japonica_validation_features_tank = japonica_validation_features[japonica_validation_features['tank_id']==tank]\n",
    "\n",
    "# 하루 동안의 데이터 추출\n",
    "one_day_data = japonica_validation_features_tank.loc['2021-08-27 00:00:00':'2021-08-27 23:59:59']\n",
    "oneday_X_test = one_day_data[feature_Learning]\n",
    "oneday_y_test = one_day_data[['do_mg']]\n",
    "\n",
    "oneday_X_test_reshape = np.asarray(oneday_X_test, dtype=np.float64)\n",
    "oneday_X_test_reshape = oneday_X_test_reshape.reshape((-1, 1, feature_number))\n",
    "\n",
    "# shape확인\n",
    "nCar = oneday_X_test_reshape.shape[0] # 데이터 개수\n",
    "nVar = oneday_X_test_reshape.shape[2] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )\n",
    "\n",
    "nCar = oneday_y_test.shape[0] # 데이터 개수\n",
    "nVar = oneday_y_test.shape[1] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapeNEva(model, oneday_X_test_reshape, oneday_y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "randomForest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70b1405dbb7eccb6c6e1c8a9ed845414758503858a2b16b5e7f3fe8227aad765"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
